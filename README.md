# Голосовой ассистент с нейросетевой обработкой и ускоренной озвучкой

Этот проект реализует голосового ассистента, который распознаёт голосовые команды на русском языке, отправляет запросы в модель Hugging Face (DeepSeek), получает ответы, обрабатывает их и озвучивает с возможностью ускорения воспроизведения и остановки голосом.

## Основные возможности

- Ожидание ключевой фразы ("привет"), после чего запускается запись запроса.
- Отправка текста запроса в Hugging Face API (модель DeepSeek).
- Очистка текста ответа от лишнего markdown и ссылок.
- Озвучивание ответа с ускорением темпа произношения (пример выходного файла `voice.mp3`).
- Возможность голосовой команды "стоп" для остановки озвучки и возврата к ожиданию ключевой фразы.
- Поддержка многократного взаимодействия с ассистентом в цикле.

## Требования

- Python 3.7+
- Библиотеки:
  - `speech_recognition`
  - `gtts`
  - `requests`
  - `pygame`
  - `pydub`
- Для работы `pydub` необходим установленный в системе `ffmpeg`.

## Установка зависимостей

pip install speechrecognition gtts requests pygame pydub


Для установки ffmpeg в Ubuntu/Debian:

sudo apt install ffmpeg


## Запуск

Запустите программу командой:

python3 speech.py 2>/dev/null


Это запустит ассистента и уберёт лишние звуковые логи ALSA из консоли.

## Файл `voice.mp3`

`voice.mp3` — это пример выходного аудиофайла ассистента после синтеза речи и применения ускорения темпа.

## Настройка

- Замените `"YOUR_HF_KEY"` в переменной `HF_API_TOKEN` в файле `speech.py` на ваш Hugging Face API-токен.
- При необходимости поменяйте модель в функции `query_huggingface_chat`.

## Лицензия

MIT License
